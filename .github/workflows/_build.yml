# **what?**
# Build release artifacts and store them to S3 bucket if they do not already exist.
#
# Build artifacts get stored in S3 to a bucket with the following directory structure:
#       "s3://<s3_bucket>/<org>/<repo>/<version>/<commit>/"
#   ex: "s3://core-team-artifacts/dbt-labs/dbt-core/1.2.3/ce98e6f067d9fa63a9b213bf99ebaf0c29d2b7eb/"
#
# Inputs:
#  sha: the commit to attache to this release
#  version_number: version number for the release (ex: 1.2.3rc2)
#  build_script_path: Path to the build script
#  s3_bucket: Bucket name
#  package_test_command: Command to use to check package runs
#   
# **why?**
# Reusable and consistent build process.
#
# **when?**
# Call when you have a commit to build and want to trigger a release.
#

name: Build

on:
  workflow_call:
    inputs:
      sha:
        required: true
        type: string
      version_number:
        required: true
        type: string
      build_script_path:
        required: true
        default: "scripts/build-dist.sh"
        type: string
      s3_bucket_name:
        required: true
        default: "core-team-artifacts"
        type: string
      package_test_command:
        required: true
        default: "dbt --version"
        type: string
    # pass through secrets so every repo can have their own and won't depend on a name
    secrets:
      AWS_ACCESS_KEY_ID:
        description: AWS Access Key ID
        required: true
      AWS_SECRET_ACCESS_KEY:
        description: AWS Access Key
        required: true
    outputs:
      CHANGELOG_PATH: ${{ jobs.build-changelog-path.outputs.changelog_path }}

permissions:
  contents: write
  # this will be needed if we go with OIDC for auth instead of manageing secrets in github for AWS
  # id-token: write  # https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-cloud-providers#adding-permissions-settings

env:
  # include commit in path in case release commit gets updates on subsequent runs
  s3_bucket: "s3://${{ inputs.s3_bucket_name }}/${{ github.repository }}/${{ inputs.version_number }}/${{ inputs.sha }}"
  artifact_retention_days: 2

jobs:
  log-inputs:
    runs-on: ubuntu-latest
    steps:
      - name: Print variables
        run: |
            echo The last commit sha in the release: ${{ inputs.sha }}
            echo The release version number: ${{ inputs.version_number }}
            echo The build_script_path: ${{ inputs.build_script_path }}
            echo The s3_bucket_name: ${{ inputs.s3_bucket_name }}
            echo The package_test_command: ${{ inputs.package_test_command }}

  build-changelog-path:
    # the changelog uses semver per https://semver.org/ so we need to build the path to the file to use it in the release notes
    # TODO: use the path built in `_release-prep.yml`
    runs-on: ubuntu-latest
    outputs:
      changelog_path: ${{ steps.set_path.outputs.changelog_path }}

    steps:

      - name: Check out the repository
        uses: actions/checkout@v3
        with:
          ref: ${{ inputs.sha }}

      - name: Audit Version and Parse Into Parts
        id: semver
        uses: dbt-labs/actions/parse-semver@v1
        with:
          version: ${{ inputs.version_number }}

      - name: Set Changelog Path
        id: generate_path
        run: |
          if [[ ${{ steps.semver.outputs.is-pre-release }} -eq 1 ]]
          then
            echo '::set-output name=changelog_path::.changes/${{ steps.semver.outputs.base-version }}-${{ steps.semver.outputs.pre-release }}.md'
          else
            echo '::set-output name=changelog_path::.changes/${{ steps.semver.outputs.version }}.md'
          fi
      
      - name: Audit Changelog Exists
        run: |
          if [ -f "${{ steps.generate_path.outputs.changelog_path }}" ]; then
            echo "${{ steps.generate_path.outputs.changelog_path }} exists."
          else
              echo "${{ steps.generate_path.outputs.changelog_path }} does not exist!"
              echo "The changelog for this release must exists before running this workflow."
              exit 1
          fi

      - name: Set Changelog Path
        id: set_path
        run: |
          echo '::set-output name=changelog_path::${{ steps.generate_path.outputs.changelog_path }}'

  check-build-exists:
    needs: [build-changelog-path]
    runs-on: ubuntu-latest
    outputs:
      exists: ${{ steps.set_existence.outputs.exists }}
  
    steps:
      
      - name: Configure AWS credentials from Test account
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1
      
      - name: Copy Artifacts from S3 via CLI
        run: |
          aws s3 cp ${{ env.s3_bucket }} . --recursive  # since it's an entire directory
      
      - name: Check file existence
        id: check_files
        uses: andstor/file-existence-action@v1
        with:
          # TODO: is this a good check?  first pass...
          files: "${{ needs.build-changelog-path.outputs.changelog_path }}, dist/*.tar.gz, dist/*.whl"

      # upload the files downloaded from S3 to artifacts so we don't have to keep 
      # downloading from S3
      - name: upload artifacts
        if: steps.check_files.outputs.files_exists == 'true'
        uses: actions/upload-artifact@v2
        with:
          name: ${{ inputs.version_number }}
          path: |
            dist/
            ${{ needs.build-changelog-path.outputs.changelog_path }}
          if-no-files-found: error
          retention-days: ${{ env.artifact_retention_days }}
      
      - name: Set Exisistence for Other Jobs
        id: set_existence
        run: echo '::set-output name=exists::${{steps.check_files.outputs.files_exists}}'

  skip-build:
    runs-on: ubuntu-latest
    needs: [check-build-exists]
    if: needs.check-build-exists.outputs.exists == 'true'

    steps:
      - name: Build Exists, Skip To Test
        run: |
          echo A build already exists for version ${{inputs.version_number}}, skipping build job

  build-packages:
    runs-on: ubuntu-latest
    needs: [check-build-exists, build-changelog-path]
    if: needs.check-build-exists.outputs.exists == 'false'

    outputs:
      finished: ${{ steps.set_success.outputs.finished }}

    steps:

      - name: Check out the repository
        uses: actions/checkout@v3
        with:
          # persist-credentials: false  # TODO: with this false I get an error checking it out, it's what existed in previous release version though
          ref: ${{ inputs.sha }}

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.8

      - name: Install python dependencies
        run: |
          pip install --user --upgrade pip
          pip install --upgrade setuptools wheel twine check-wheel-contents
          pip --version

      - name: Build distributions
        run: ./${{ inputs.build_script_path }}

      - name: Show distributions
        run: ls -lh dist/

      - name: Check distribution descriptions
        run: |
          twine check dist/*

      - name: Check wheel contents
        run: |
          check-wheel-contents dist/*.whl --ignore W007,W008

      - name: upload artifacts
        uses: actions/upload-artifact@v2
        with:
          name: ${{ inputs.version_number }}
          path: |
            dist/
            !dist/dbt-${{ inputs.version_number }}.tar.gz
            ${{ needs.build-changelog-path.outputs.changelog_path }}
          if-no-files-found: error
          retention-days: ${{ env.artifact_retention_days }}

  test-build:
    runs-on: ubuntu-latest
    needs: [build-packages]
  
    steps:
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.8

      - name: Install python dependencies
        run: |
          pip install --user --upgrade pip
          pip install --upgrade wheel
          pip --version

      - uses: actions/download-artifact@v3
        with:
          name: ${{ inputs.version_number }}
          path: .

      - name: Display structure of all downloaded files
        run: ls -R
      
      - name: Show distributions
        run: ls -lh dist/

      - name: Install wheel distributions
        run: |
          find ./dist/*.whl -maxdepth 1 -type f | xargs pip install --force-reinstall --find-links=dist/

      - name: Check wheel distributions
        run: |
          ${{ inputs.package_test_command }}

      - name: Install source distributions
        run: |
          find ./dist/*.gz -maxdepth 1 -type f | xargs pip install --force-reinstall --find-links=dist/

      - name: Check source distributions
        run: |
          ${{ inputs.package_test_command }}

  upload-artifacts-aws:
    runs-on: ubuntu-latest
    needs: [test-build, build-changelog-path]
  
    steps:
      - uses: actions/download-artifact@v3
        with:
          name: ${{inputs.version_number}}
          path: .

      - name: Display structure of all downloaded files
        run: ls -R

      - name: Configure AWS credentials
      # TODO: do i need to do this once per job?
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Upload Artifacts to S3 via CLI
        run: |
          aws s3 cp . ${{ env.s3_bucket }} --recursive  # since it's an entire directory